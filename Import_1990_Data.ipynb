{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read 'stf301ca.dbf' into DataFrame 'stf301ca'\n",
      "Successfully read 'stf301nv.dbf' into DataFrame 'stf301nv'\n",
      "Successfully read 'stf302ca.dbf' into DataFrame 'stf302ca'\n",
      "Successfully read 'stf302nv.dbf' into DataFrame 'stf302nv'\n",
      "Successfully read 'stf309ca.dbf' into DataFrame 'stf309ca'\n",
      "Successfully read 'stf309nv.dbf' into DataFrame 'stf309nv'\n",
      "Successfully read 'stf314ca.dbf' into DataFrame 'stf314ca'\n",
      "Successfully read 'stf314nv.dbf' into DataFrame 'stf314nv'\n",
      "Successfully read 'stf327ca.dbf' into DataFrame 'stf327ca'\n",
      "Successfully read 'stf327nv.dbf' into DataFrame 'stf327nv'\n",
      "Successfully read 'stf330ca.dbf' into DataFrame 'stf330ca'\n",
      "Successfully read 'stf330nv.dbf' into DataFrame 'stf330nv'\n",
      "Successfully read 'stf333ca.dbf' into DataFrame 'stf333ca'\n",
      "Successfully read 'stf333nv.dbf' into DataFrame 'stf333nv'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "#This doesn't come with the standard esri virtual environment so it needs to be added to a cloned env\n",
    "from dbfread import DBF\n",
    "\n",
    "from arcgis.features import FeatureLayer\n",
    "\n",
    "\n",
    "def read_all_dbf_files(folder_path):\n",
    "    # Get a list of all DBF files in the folder\n",
    "    dbf_files = [file for file in os.listdir(folder_path) if file.endswith('.dbf')]\n",
    "    \n",
    "    # Create a dictionary to store the DataFrames\n",
    "    dataframes = {}\n",
    "    \n",
    "    # Loop through each DBF file and read it into a DataFrame\n",
    "    for file in dbf_files:\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        df_name = os.path.splitext(file)[0]  # Use the file name (without extension) as DataFrame name\n",
    "        \n",
    "        try:\n",
    "            # Use dbfread to read the DBF file into a DataFrame\n",
    "            table = DBF(file_path)\n",
    "            df = pd.DataFrame(iter(table))\n",
    "            dataframes[df_name] = df\n",
    "            print(f\"Successfully read '{file}' into DataFrame '{df_name}'\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading '{file}': {str(e)}\")\n",
    "    \n",
    "    return dataframes\n",
    "\n",
    "# Replace 'folder_path' with the path to the folder containing the DBF files\n",
    "folder_path = 'C:/Users/amcclary/Documents/GitHub/Demographics/1990_Tables'\n",
    "all_dataframes = read_all_dbf_files(folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the Nevada and California tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_dataframes_by_prefix(dataframes_dict, prefix_length):\n",
    "    combined_dataframes = {}\n",
    "    \n",
    "    # Group DataFrames by the first x characters of their names\n",
    "    groups = {}\n",
    "    for name, df in dataframes_dict.items():\n",
    "        prefix = name[:prefix_length]\n",
    "        if prefix not in groups:\n",
    "            groups[prefix] = []\n",
    "        groups[prefix].append(df)\n",
    "    \n",
    "    # Combine DataFrames in each group using pd.concat\n",
    "    for prefix, dfs in groups.items():\n",
    "        if len(dfs) > 1:\n",
    "            combined_dataframes[prefix] = pd.concat(dfs, ignore_index=True)\n",
    "        else:\n",
    "            combined_dataframes[prefix] = dfs[0]\n",
    "    \n",
    "    return combined_dataframes\n",
    "\n",
    "# Assuming you already have a dictionary of dataframes named 'all_dataframes'\n",
    "# Replace 'prefix_length' with the number of characters you want to consider for grouping\n",
    "prefix_length = 6\n",
    "combined_dataframes = combine_dataframes_by_prefix(all_dataframes, prefix_length)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specify which variables we want to include and what we want them named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_list = pd.read_csv('Census_Variable_Lists/1990_variables_age_grouping.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download tahoe geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    " \n",
    "service_url = 'https://maps.trpa.org/server/rest/services/Demographics/FeatureServer/27'\n",
    "\n",
    "feature_layer = FeatureLayer(service_url)\n",
    "tahoe_geometry_fields = ['YEAR', 'STATE', 'GEOGRAPHY', 'GEOID', 'TRPAID', 'NEIGHBORHOOD']\n",
    "query_result = feature_layer.query(out_fields=\",\".join(tahoe_geometry_fields))\n",
    "# Convert the query result to a list of dictionaries\n",
    "feature_list = query_result.features\n",
    "\n",
    "# Create a pandas DataFrame from the list of dictionaries\n",
    "tahoe_geometry = pd.DataFrame([feature.attributes for feature in feature_list])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter all the dataframes down to sum level 140 (tract level) and state, county and tract are in the ones we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter all the dataframes down to sum level 140 and state, county and tract are in the ones we want\n",
    "# df = df[df['TRPAID'].isin(tahoe_geometry['TRPAID'])]\n",
    "# Loop through dictionary\n",
    "# Filter on 140\n",
    "# Match tractnumbers\n",
    "\n",
    "def filter_1990_table(df, tahoe_geometry, grouping_columns):\n",
    "    df = df.loc[df['SUMLEV']=='140']\n",
    "    df['TRACT'] = df['TRACTBNA'].str.pad(width=6, side='right', fillchar='0')\n",
    "    df['TRPAID'] = df['STATEFP']+df['CNTY']+df['TRACT']+'1990'\n",
    "    df= df[df['TRPAID'].isin(tahoe_geometry['TRPAID'])]\n",
    "    df = df.melt(id_vars=grouping_columns)\n",
    "    df =  pd.merge(df, tahoe_geometry[['TRPAID', 'NEIGHBORHOOD']], on='TRPAID', how= 'left')\n",
    "    df['year_sample']='1990'\n",
    "    df['sample_level']='tract'\n",
    "    df['dataset']= 'dec/sf3'\n",
    "    df['census_geom_year'] = '1990'\n",
    "    return df\n",
    "\n",
    "df_test = combined_dataframes['stf301']\n",
    "\n",
    "def filter_1990_table_non_tahoe(df, grouping_columns):\n",
    "    county_states ={\n",
    "        '06': ['017','061'],\n",
    "        '32': ['005', '031', '510']\n",
    "    }\n",
    "    state_names={\n",
    "        '06':'CA',\n",
    "        '32':'NV'\n",
    "    }\n",
    "    Combined_codes = ['05006017', '05006061', '05032005','05032031','05032510']\n",
    "    df['combined_code']=df['SUMLEV']+df['STATEFP']+df['CNTY']\n",
    "    df = df.loc[df['combined_code'].isin(Combined_codes)]\n",
    "    df = df.melt(id_vars=grouping_columns)\n",
    "    df['year_sample']='1990'\n",
    "    df['sample_level']='county'\n",
    "    df['dataset']= 'dec/sf3'\n",
    "    df['census_geom_year'] = '1990'\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test1 = filter_1990_table_non_tahoe(combined_dataframes['stf301'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Melt data to change it to long format "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_columns = ['SUMLEV', 'STATEFP', 'CNTY', 'COUSUBFP', 'PLACEFP', 'TRACTBNA', 'BLCKGR', 'LOGRECNU', 'TRACT', 'TRPAID']\n",
    "melted_dataframes = []\n",
    "for name, df in combined_dataframes.items():\n",
    "    df1 = filter_1990_table(df, tahoe_geometry, grouping_columns)\n",
    "    melted_dataframes.append(df1)\n",
    "combined_dataframe = pd.concat(melted_dataframes, ignore_index= True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataframe.to_excel('combined_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_columns = ['SUMLEV', 'STATEFP', 'CNTY']\n",
    "melted_dataframes = []\n",
    "for name, df in combined_dataframes.items():\n",
    "    df1 = filter_1990_table_non_tahoe(df, grouping_columns)\n",
    "    melted_dataframes.append(df1)\n",
    "combined_dataframe = pd.concat(melted_dataframes, ignore_index= True)    \n",
    "combined_dataframe_withvariables = pd.merge(combined_dataframe, variable_list, on='variable', how= 'inner')\n",
    "combined_dataframe_withvariables.to_excel('data_1990_age_county.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['SUMLEV', 'STATEFP', 'CNTY', 'year_sample', 'sample_level', 'dataset', 'census_geom_year', 'variable_category', 'census_category']\n"
     ]
    }
   ],
   "source": [
    "group_columns = [column for column in combined_dataframe_withvariables if column not in ['value', 'variable', \n",
    "    'variable_name', 'MarginOfError','Unnamed: 5', 'Table', 'File']]\n",
    "grouping_prefix = \"TRPA Census Age Sex Categories Grouped:\"\n",
    "#grouped_data = joined_data.groupby(group_columns, as_index=False)['value'].sum()    \n",
    "print(group_columns)\n",
    "grouped_data = combined_dataframe_withvariables.groupby(group_columns, as_index=False, dropna=False).agg({'value':'sum',\n",
    "                                                                        'variable':lambda x: grouping_prefix +  ', '.join(x)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data.to_excel('grouped_1990_age_non_tahoe.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataframe_withvariables = pd.merge(combined_dataframe, variable_list, on='variable', how= 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataframe_withvariables.to_excel('data_1990_age.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_columns = ['SUMLEV', 'STATEFP', 'CNTY', 'COUSUBFP', 'PLACEFP', 'TRACTBNA', 'BLCKGR', 'LOGRECNU', 'TRACT', 'TRPAID']\n",
    "\n",
    "df1990_melted = df1990.melt(id_vars=grouping_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_columns = [column for column in combined_dataframe_withvariables if column not in ['value', 'variable', \n",
    "    'variable_name', 'MarginOfError','Unnamed: 5', 'Table', 'NEIGHBORHOOD', 'File']]\n",
    "grouping_prefix = \"TRPA Census Age Sex Categories Grouped:\"\n",
    "#grouped_data = joined_data.groupby(group_columns, as_index=False)['value'].sum()    \n",
    "print(group_columns)\n",
    "grouped_data = combined_dataframe_withvariables.groupby(group_columns, as_index=False, dropna=False).agg({'value':'sum',\n",
    "                                                                        'variable':lambda x: grouping_prefix +  ', '.join(x)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data.to_excel('grouped_1990_age.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
