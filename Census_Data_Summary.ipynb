{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up and import tahoe geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import arcpy\n",
    "from arcgis.features import FeatureLayer\n",
    "\n",
    "service_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/27'\n",
    "\n",
    "feature_layer = FeatureLayer(service_url)\n",
    "tahoe_geometry_fields = ['YEAR', 'STATE', 'GEOGRAPHY', 'GEOID', 'TRPAID', 'NEIGHBORHOOD']\n",
    "query_result = feature_layer.query(out_fields=\",\".join(tahoe_geometry_fields))\n",
    "# Convert the query result to a list of dictionaries\n",
    "feature_list = query_result.features\n",
    "\n",
    "# Create a pandas DataFrame from the list of dictionaries\n",
    "tahoe_geometry = pd.DataFrame([feature.attributes for feature in feature_list])\n",
    "\n",
    "county_lookup = {\n",
    "    '005': 'Douglas County (Tahoe Basin)',\n",
    "    '017': 'El Dorado County (Tahoe Basin)',\n",
    "    '031': 'Washoe County (Tahoe Basin)',\n",
    "    '061': 'Placer County (Tahoe Basin)'\n",
    "}\n",
    "\n",
    "state_lookup = {\n",
    "    '32': 'Nevada',\n",
    "    '06': 'California'\n",
    "}\n",
    "\n",
    "inflation_adjustment = {\n",
    "    '2000': 1.57,\n",
    "    '2010': 1.24\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_or_append_df(df, summary_df):\n",
    "    if df.empty:\n",
    "        df = summary_df.copy()\n",
    "    else:\n",
    "        df = pd.concat([df, summary_df])\n",
    "    return df\n",
    "\n",
    "def calculate_median_value(df, bin_column, sort_column, count_column, category_field, category,grouping_variables, cumulative_sorting_variables):\n",
    "        # Create a new DataFrame to avoid modifying the original one\n",
    "    #change value to count column\n",
    "    #Do we need to handle excluding non-tahoe things here or should we do it in the input?\n",
    "    summary_df = df.copy()\n",
    "    summary_df[count_column]=summary_df[count_column].astype(int)\n",
    "    #summary_df=summary_df.loc[summary_df[count_column]!='510']\n",
    "    summary_df = summary_df.groupby(grouping_variables)[count_column].sum()\n",
    "    summary_df = summary_df.reset_index()\n",
    "    #This handles -6666 values that they sometimes add for unknown data\n",
    "    summary_df = summary_df.loc[summary_df[count_column]>=0]\n",
    "    \n",
    "    \n",
    "    summary_df= summary_df.loc[summary_df[category_field]==category]\n",
    "    # Sort the DataFrame based on the variable name column\n",
    "    # This depends on the fact that census variables start with the lowest value and go up \n",
    "    #This needs to all be rethought to have some kind of window function to handle multiple years\n",
    "    summary_df.sort_values(by=sort_column, inplace=True)\n",
    "    summary_df = summary_df.reset_index()\n",
    "    \n",
    "    # Extract lower and upper limits from bin categories\n",
    "    #This uses regex to find numbers and removes commas to make numbers numbers \n",
    "    pattern = r'(\\d+[\\d,]*)'\n",
    "    summary_df['temp'] = summary_df[bin_column].str.replace(',', '').str.findall(pattern)\n",
    "    #Looks for values that have two numbers and puts empty placeholders for the ones that only have one (upper and lower)\n",
    "    summary_df[['Lower', 'Upper']] = summary_df['temp'].apply(lambda x: pd.Series(x[:2]) if len(x) == 2 else pd.Series([None, None]))\n",
    "    summary_df['Lower'] = summary_df['Lower'].astype(float)\n",
    "    summary_df['Upper'] = summary_df['Upper'].astype(float)\n",
    "    # Handle first category\n",
    "    \n",
    "    first_upper = float(summary_df['temp'].iloc[0][0])\n",
    "    low_variable_name = summary_df[bin_column].iloc[0]\n",
    "\n",
    "    summary_df.loc[summary_df[bin_column]==low_variable_name,'Lower'] = 0  # Set lower value to 0\n",
    "    summary_df.loc[summary_df[bin_column]==low_variable_name,'Upper'] = first_upper\n",
    "\n",
    "    \n",
    "    # Handle last category\n",
    "    \n",
    "    last_lower = float(summary_df['temp'].iloc[-1][0])\n",
    "    upper_variable_name = summary_df[bin_column].iloc[-1]\n",
    "    summary_df.loc[summary_df[bin_column]==upper_variable_name,'Lower'] = last_lower\n",
    "    summary_df.loc[summary_df[bin_column]==upper_variable_name,'Upper'] = np.inf  # Set upper value to infinity\n",
    "    summary_df[count_column]= summary_df[count_column].astype(float)   \n",
    "    # Calculate cumulative count\n",
    "    cumulative_grouping_variables = grouping_variables\n",
    "\n",
    "    cumulative_grouping_variables.remove(bin_column)\n",
    "    cumulative_grouping_variables.remove(sort_column)\n",
    "\n",
    "    #Update this to be parameterized\n",
    "    \n",
    "    summary_df.sort_values(by=cumulative_sorting_variables, inplace=True)\n",
    "    summary_df = summary_df.reset_index()\n",
    "    summary_df['cumulative_sum'] = summary_df.groupby(cumulative_grouping_variables, as_index=False)[count_column].cumsum()\n",
    "    summary_df['TotalSum'] = summary_df.groupby(cumulative_grouping_variables, as_index=False)[count_column].transform('sum')\n",
    "    summary_df['previous_cumulative'] = summary_df['cumulative_sum'].shift()\n",
    "\n",
    "    summary_df = summary_df.loc[summary_df['cumulative_sum']>=(summary_df['TotalSum']/2)].groupby(cumulative_grouping_variables, as_index=False).first()\n",
    "\n",
    "    summary_df['cumulative_difference'] = summary_df['TotalSum']  / 2 - summary_df['previous_cumulative']\n",
    "    summary_df['interpolation_ratio'] = summary_df['cumulative_difference'] /  (summary_df['cumulative_sum']- summary_df['previous_cumulative'])\n",
    "    summary_df['median_value'] = summary_df['Lower'] + summary_df['interpolation_ratio'] * (summary_df['Upper'] - summary_df['Lower'])\n",
    "    \n",
    "    \n",
    "    return summary_df\n",
    "\n",
    "\n",
    "def categorize_values(census_df, category_csv, category_column, grouping_prefix):\n",
    "    categories = pd.read_csv(category_csv)    \n",
    "    census_df['value'] = census_df['value'].astype(float)\n",
    "    joined_data = census_df.merge(categories, on = 'variable_code', how = 'left')\n",
    "    joined_data.sort_values(by='variable_code', inplace=True)\n",
    "    #This will get rid of any extra columns in the category_csv\n",
    "    group_columns = [column for column in census_df if column not in ['value', 'variable_code', 'variable_name', 'MarginOfError','OBJECTID']]\n",
    "    group_columns.append(category_column)\n",
    "    #grouped_data = joined_data.groupby(group_columns, as_index=False)['value'].sum()    \n",
    "    print(group_columns)\n",
    "    grouped_data = joined_data.groupby(group_columns, as_index=False, dropna=False).agg({'value':'sum',\n",
    "                                                                           'variable_code':lambda x: grouping_prefix +  ', '.join(x)})\n",
    "    \n",
    "    #Need to return this formatted for appending to the table - need to get locations of variable_code and variable name, \n",
    "    #add them in as columns in those locations and then populate them with category column nanme\n",
    "    var_code_col_location = census_df.columns.get_loc('variable_code')\n",
    "    var_name_col_location = census_df.columns.get_loc('variable_name')\n",
    "    var_moe_col_location = census_df.columns.get_loc('MarginOfError')\n",
    "    grouped_data.insert(var_moe_col_location, 'MarginOfError', '')\n",
    "    #grouped_data.insert(var_code_col_location, 'variable_code','Grouped Value')\n",
    "    grouped_data.insert(var_name_col_location, 'variable_name','')\n",
    "    #grouped_data['variable_code'] = grouped_data['variable_code'] +  '_Grouped'\n",
    "    grouped_data['variable_name'] = grouped_data[category_column]\n",
    "    grouped_data['dataset']= grouping_prefix + grouped_data['dataset']\n",
    "    grouped_data['variable_category']= grouping_prefix +  grouped_data['variable_category'] \n",
    "    columns_to_keep = [column for column in census_df if column not in ['OBJECTID']]\n",
    "    grouped_data= grouped_data[columns_to_keep]\n",
    "    return grouped_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Basin Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data for Basin Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/28'\n",
    "\n",
    "feature_layer = FeatureLayer(service_url)\n",
    "query_result = feature_layer.query()\n",
    "# Convert the query result to a list of dictionaries\n",
    "feature_list = query_result.features\n",
    "\n",
    "# Create a pandas DataFrame from the list of dictionaries\n",
    "all_data = pd.DataFrame([feature.attributes for feature in feature_list])\n",
    "\n",
    "all_data_clean = all_data.loc[(all_data['county']!='510')&(all_data['value']>=0)]\n",
    "all_data_clean.loc[all_data_clean['county'].isin(['005','017']),'north_south'] = 'South Lake'\n",
    "all_data_clean.loc[all_data_clean['county'].isin(['031','061']),'north_south'] = 'North Lake'\n",
    "all_data_clean['county_name'] = all_data_clean['county'].apply(lambda x: county_lookup.get(x, None))\n",
    "all_data_clean['state_name'] = all_data_clean['state'].apply(lambda x: state_lookup.get(x, None))\n",
    "\n",
    "\n",
    "all_data_clean = all_data_clean.dropna(subset='value')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summed Estimates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Population Totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_population_data = all_data_clean.loc[(all_data_clean['variable_name']=='Total Population')]\n",
    "filtered_population_data\n",
    "summarized_population_data_basin = filtered_population_data.groupby([ 'dataset', 'variable_code', 'year_sample'], as_index=False).sum(['value'])\n",
    "summarized_population_data_county = filtered_population_data.groupby(['dataset', 'variable_code', 'year_sample', 'county_name'], as_index=False).sum(['value'])\n",
    "summarized_population_data_north_south = filtered_population_data.groupby(['dataset', 'variable_code', 'year_sample', 'north_south'], as_index=False).sum(['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_across_levels(df, variable_name, category_name):\n",
    "    filtered_df = df.loc[(df['variable_name']==variable_name)]\n",
    "    basin_summary = filtered_df.groupby([ 'dataset', 'sample_level', 'variable_name', 'variable_code', 'year_sample'], as_index=False).sum(['value'])\n",
    "    county_summary = filtered_df.groupby(['dataset', 'sample_level', 'variable_name', 'variable_code', 'year_sample', 'county_name'], as_index=False).sum(['value'])\n",
    "    north_south_summary = filtered_df.groupby(['dataset', 'sample_level', 'variable_name', 'variable_code', 'year_sample', 'north_south'], as_index=False).sum(['value'])\n",
    "    state_summary = filtered_df.groupby(['dataset', 'sample_level', 'variable_name', 'variable_code', 'year_sample', 'state_name'], as_index=False).sum(['value'])\n",
    "    #basin_summary.rename(columns = {'variable_code': 'Code', 'year_sample': 'Year'})\n",
    "    basin_summary['Geography'] = 'Basin'\n",
    "    county_summary['Geography'] = county_summary['county_name'] \n",
    "    north_south_summary['Geography'] = north_south_summary['north_south']\n",
    "    state_summary['Geography'] = state_summary['state_name']\n",
    "    columns_to_keep = ['variable_code','variable_name', 'value', 'Geography', 'year_sample', 'dataset', 'sample_level']\n",
    "    basin_summary= basin_summary[columns_to_keep]\n",
    "    county_summary = county_summary[columns_to_keep]\n",
    "    north_south_summary = north_south_summary[columns_to_keep]\n",
    "    state_summary = state_summary[columns_to_keep]\n",
    "    combined_summary = pd.concat([basin_summary, county_summary, north_south_summary, state_summary], ignore_index=True)\n",
    "    #if neighborhood_yn == 'Yes':\n",
    "    #    neighborhood_summary = filtered_df.groupby(['dataset', 'sample_level', 'variable_name', 'variable_code', 'year_sample', 'NEIGHBORHOOD'], as_index=False).sum(['value'])\n",
    "        #basin_summary.rename(columns = {'variable_code': 'Code', 'year_sample': 'Year'})\n",
    "    #    neighborhood_summary['Geography'] = neighborhood_summary['NEIGHBORHOOD']\n",
    "    #    combined_summary = pd.concat([combined_summary, neighborhood_summary], ignore_index=True)\n",
    "    combined_summary['Category'] = category_name\n",
    "    return combined_summary\n",
    "def sum_multiple_variables(df, variable_list, variable_category):\n",
    "    df_values=pd.DataFrame()\n",
    "    for variable in variable_list:\n",
    "        summed_df = sum_across_levels(df,variable, variable_category)\n",
    "        df_values = create_or_append_df(df_values, summed_df)\n",
    "    return df_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Climate Dashboard Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_variables = pd.read_csv('Census_Category_Lists/Climate_Dashboard_Age.csv')\n",
    "variables = list(summary_variables['Variables'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_data = all_data_clean.loc[all_data_clean['variable_category']=='TRPA 5-year Age CategoriesAge']\n",
    "summed_ages = sum_multiple_variables(filtered_data, variables,'Age')\n",
    "summed_ages.to_excel('summed_ages.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_heating = sum_across_levels(all_data_clean,'Total Heating Methods','House Heating Fuel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables=['Renter Occupied: Two Or More Races Householder', 'Owner Occupied: Two Or More Races Householder']\n",
    "df = sum_multiple_variables(all_data_clean,variables,'Tenure by Race')\n",
    "df.to_excel('dashboard_fill_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables=['Total Heating Methods', 'Utility gas', 'Bottled, tank, or LP gas',\n",
    "           'Electricity','Fuel oil, kerosene, etc.', 'No fuel used',\n",
    "           'Coal or coke','Wood','Solar energy','Other fuel']\n",
    "heating_df = sum_multiple_variables(all_data_clean,variables,'House Heating Fuel')\n",
    "heating_df.to_excel('heating_summaries.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables=['Total population:  Hispanic or Latino', 'Total population:  Not Hispanic or Latino; White alone','Total population:  Not Hispanic or Latino; Black or African American alone',\n",
    "           'Total population:  Not Hispanic or Latino; American Indian and Alaska Native alone', 'Total population:  Not Hispanic or Latino; Asian alone',\n",
    "           'Total population:  Not Hispanic or Latino; Native Hawaiian and Other Pacific Islander alone',\n",
    "           'Total population:  Not Hispanic or Latino; Some other race alone',\n",
    "           'Total population:  Not Hispanic or Latino; Two or more races',\n",
    "           'Total Heating Methods', 'Utility gas', 'Bottled, tank, or LP gas',\n",
    "           'Electricity','Fuel oil, kerosene, etc.','Coal or coke','Wood','Solar energy','Other fuel'\n",
    "           'Owner Occupied: American Indian And Alaska Native Alone Householder',\n",
    "'Owner Occupied: Asian Alone Householder',\n",
    "'Owner Occupied: Black Or African American Alone Householder',\n",
    "'Owner Occupied: Householder 25 To 34 Years',\n",
    "'Owner Occupied: Householder 35 To 44 Years',\n",
    "'Owner Occupied: Householder 45 To 54 Years',\n",
    "'Owner Occupied: Householder 55 To 59 Years',\n",
    "'Owner Occupied: Householder 60 To 64 Years',\n",
    "'Owner Occupied: Householder 65 To 74 Years',\n",
    "'Owner Occupied: Householder 75 To 84 Years',\n",
    "'Owner Occupied: Householder 85 Years And Over',\n",
    "'Owner Occupied: Native Hawaiian And Other Pacific Islander Alone Householder',\n",
    "'Owner Occupied: Some Other Race Alone Householder',\n",
    "'Owner Occupied: White Alone Householder',\n",
    "'Renter Occupied: American Indian And Alaska Native Alone Householder',\n",
    "'Renter Occupied: Asian Alone Householder',\n",
    "'Renter Occupied: Black Or African American Alone Householder',\n",
    "'Renter Occupied: Householder 15 To 24 Years',\n",
    "'Renter Occupied: Householder 25 To 34 Years',\n",
    "'Renter Occupied: Householder 35 To 44 Years',\n",
    "'Renter Occupied: Householder 45 To 54 Years',\n",
    "'Renter Occupied: Householder 55 To 59 Years',\n",
    "'Renter Occupied: Householder 60 To 64 Years',\n",
    "'Renter Occupied: Householder 65 To 74 Years',\n",
    "'Renter Occupied: Householder 75 To 84 Years',\n",
    "'Renter Occupied: Householder 85 Years And Over',\n",
    "'Renter Occupied: Native Hawaiian And Other Pacific Islander Alone Householder',\n",
    "'Renter Occupied: Some Other Race Alone Householder',\n",
    "'Renter Occupied: Total',\n",
    "'Renter Occupied: White Alone Householder',\n",
    "'Total: American Indian And Alaska Native Alone Householder',\n",
    "'Total: Asian Alone Householder',\n",
    "'Total: Black Or African American Alone Householder',\n",
    "'Total: Native Hawaiian And Other Pacific Islander Alone Householder',\n",
    "'Total: Some Other Race Alone Householder',\n",
    "'Total: Two Or More Races Householder',\n",
    "'Total: White Alone Householder'\n",
    "]\n",
    "race_df = sum_multiple_variables(all_data_clean,variables,'Dashboard Variables')\n",
    "race_df.to_excel('Dashboard_Summary.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables=['Owner Occupied: Householder 15 To 24 Years', 'Owner Occupied: Total', 'Renter Occupied: Two Or More Races Householder',\n",
    "           'Owner Occupied: Two Or More Races Householder','Owner Occupied: American Indian And Alaska Native Alone Householder']\n",
    "heating_df = sum_multiple_variables(all_data_clean,variables,'Dashboard Variables')\n",
    "heating_df.to_excel('dashboard_summaries_2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_income_data = all_data_clean.loc[(all_data_clean['variable_category']=='Household Income')]\n",
    "variable_name = '$200,000 or more'\n",
    "category_name = 'Household Income'\n",
    "rich_person_summary = sum_across_levels(all_data_clean, variable_name, category_name)\n",
    "rich_person_summary.to_excel('RichPeople.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variable_name = 'Total Population'\n",
    "category_name = 'Total Population'\n",
    "\n",
    "\n",
    "total_population_summary = sum_across_levels(all_data_clean, variable_name, category_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_population_summary = total_population_summary.loc[total_population_summary['variable_code']!='P1_001N']\n",
    "\n",
    "total_population_summary.to_excel('population_summaries.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_housing_data = all_data_clean.loc[(all_data_clean['sample_level']!='block')]\n",
    "variable_name = 'Total Housing Units'\n",
    "category_name = 'Housing Units'\n",
    "\n",
    "total_housing_units_summary = sum_across_levels(filtered_housing_data, variable_name, category_name)\n",
    "total_housing_units_summary.to_excel('total_housing_units_summary.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_housing_data = all_data_clean.loc[(all_data_clean['sample_level']!='block')]\n",
    "#variable_name = 'Total Housing Units'\n",
    "category_name = 'Housing Units'\n",
    "\n",
    "variable_list= ['Total Housing Units', 'Total Housing Units: Occupied', \n",
    "    'Total Housing Units: Vacant', 'Vacant Housing Units: Seasonal, recreational, or occasional use',\n",
    "    'Occupied Housing Units: Owner Occupied', 'Occupied Housing Units: Renter Occupied','Total Population']\n",
    "housing_unit_summary=pd.DataFrame()\n",
    "for variable in variable_list:\n",
    "    df = sum_across_levels(filtered_housing_data, variable, category_name)\n",
    "    housing_unit_summary = create_or_append_df(housing_unit_summary, df)\n",
    "\n",
    "housing_unit_summary.to_excel('housing_unit_summaries.xlsx')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2022 Summed estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_clean_2022 = all_data_clean.loc[all_data_clean['year_sample']==2022]\n",
    "variable_list= ['Total Housing Units', 'Total Housing Units: Occupied', \n",
    "    'Total Housing Units: Vacant', 'Vacant Housing Units: Seasonal, recreational, or occasional use',\n",
    "    'Occupied Housing Units: Owner Occupied', 'Occupied Housing Units: Renter Occupied', 'Total Population']\n",
    "summary_data_2022 = sum_multiple_variables(all_data_clean_2022,variable_list,'Update Categories')\n",
    "summary_data_2022.to_excel('summary_data_2022.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Median Estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouping_variables = ['variable_category', 'year_sample', 'dataset', 'variable_code', 'sample_level', 'variable_name']\n",
    "\n",
    "clean_income_data= all_data_clean.loc[(all_data_clean['county']!='510')]\n",
    "clean_income_data = clean_income_data.loc[(clean_income_data['value']>=0)]\n",
    "bin_column= 'variable_name'\n",
    "sort_column = 'variable_code'\n",
    "count_column = 'value'\n",
    "category_field = 'variable_category'\n",
    "category = 'Household Income'\n",
    "cumulative_sort_columns = ['year_sample', 'sample_level', 'variable_code']\n",
    "median_income_basin = calculate_median_value(clean_income_data, bin_column, sort_column, count_column, category_field, category,grouping_variables, cumulative_sort_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_across_levels(df, bin_column, sort_column, count_column, category_field, category,grouping_variables, cumulative_sorting_variables):\n",
    "    basin_sort_columns = cumulative_sorting_variables\n",
    "    basin_grouping_variables = grouping_variables\n",
    "    county_sort_columns = ['county_name'] + cumulative_sorting_variables\n",
    "    county_grouping_variables = grouping_variables + ['county_name']\n",
    "    north_south_sort_columns = ['north_south'] + cumulative_sorting_variables\n",
    "    north_south_grouping_variables = grouping_variables + ['north_south']\n",
    "    basin_summary = calculate_median_value(df, bin_column, sort_column, count_column, category_field, category,grouping_variables, cumulative_sorting_variables)\n",
    "    county_summary = calculate_median_value(df, bin_column, sort_column, count_column, category_field, category, county_grouping_variables, county_sort_columns)\n",
    "    north_south_summary = calculate_median_value(df, bin_column, sort_column, count_column, category_field, category, north_south_grouping_variables, north_south_sort_columns)\n",
    "    basin_summary['Geography'] = 'Basin'\n",
    "    county_summary['Geography'] = county_summary['county_name']\n",
    "    north_south_summary['Geography'] = north_south_summary['north_south']\n",
    "    columns_to_keep = ['variable_code','variable_name', 'value', 'Geography', 'year_sample', 'dataset', 'sample_level', 'median_value']\n",
    "    basin_summary= basin_summary[columns_to_keep]\n",
    "    county_summary = county_summary[columns_to_keep]\n",
    "    north_south_summary = north_south_summary[columns_to_keep]\n",
    "    combined_summary = pd.concat([basin_summary, county_summary, north_south_summary], ignore_index=True)\n",
    "    combined_summary['Category'] = category\n",
    "    return combined_summary\n",
    "\n",
    "grouping_variables = ['variable_category', 'year_sample', 'dataset', 'variable_code', 'variable_name', 'sample_level']\n",
    "\n",
    "clean_income_data= all_data_clean.loc[(all_data_clean['county']!='510')&(all_data_clean['sample_level']=='tract')]\n",
    "\n",
    "clean_income_data = clean_income_data.loc[(clean_income_data['value']>=0)]\n",
    "bin_column= 'variable_name'\n",
    "sort_column = 'variable_code'\n",
    "count_column = 'value'\n",
    "category_field = 'variable_category'\n",
    "category = 'Household Income'\n",
    "cumulative_sort_columns = ['year_sample', 'variable_code', 'sample_level']\n",
    "median_incomes = median_across_levels(clean_income_data, bin_column, sort_column, count_column, category_field, category,grouping_variables, cumulative_sort_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "median_incomes.to_excel(\"Updated_Median_Incomes.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_income_data= all_data_clean_2022\n",
    "\n",
    "clean_income_data = clean_income_data.loc[(clean_income_data['value']>=0)]\n",
    "median_incomes = median_across_levels(clean_income_data, bin_column, sort_column, count_column, category_field, category,grouping_variables, cumulative_sort_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Categorize Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize Tahoe Age data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/28'\n",
    "\n",
    "feature_layer = FeatureLayer(service_url)\n",
    "query_result = feature_layer.query()\n",
    "# Convert the query result to a list of dictionaries\n",
    "feature_list = query_result.features\n",
    "\n",
    "# Create a pandas DataFrame from the list of dictionaries\n",
    "census_data = pd.DataFrame([feature.attributes for feature in feature_list])\n",
    "age_data = census_data.loc[(census_data['variable_category']=='Age')&(census_data['sample_level']=='tract')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_categories_1990 = 'Census_Category_Lists/age_categories_1990.csv'\n",
    "dec_categories = 'Census_Category_Lists/dec_age_categories.csv'\n",
    "dec_categories_2020 = 'Census_Category_Lists/dec_age_categories_2020.csv'\n",
    "tahoe_age_1990 = age_data.loc[age_data['year_sample']==1990]\n",
    "tahoe_age_2010 = age_data.loc[age_data['year_sample']==2010]\n",
    "tahoe_age_2000 = age_data.loc[age_data['year_sample']==2000]\n",
    "tahoe_age_2020 = age_data.loc[age_data['year_sample']==2020]\n",
    "\n",
    "grouped_tahoe_age_1990 = categorize_values(tahoe_age_1990, dec_categories_1990 ,'Ten Year Category', 'TRPA 10-year Age Categories Grouped: ')\n",
    "grouped_tahoe_age_2000 = categorize_values(tahoe_age_2000, dec_categories ,'Ten Year Category', 'TRPA 10-year Age Categories Grouped: ')\n",
    "grouped_tahoe_age_2010 = categorize_values(tahoe_age_2010, dec_categories ,'Ten Year Category', 'TRPA 10-year Age Categories Grouped: ')\n",
    "grouped_tahoe_age_2020 = categorize_values(tahoe_age_2020, dec_categories_2020 ,'Ten Year Category', 'TRPA 10-year Age Categories Grouped: ')\n",
    "\n",
    "grouped_tahoe_age = pd.concat([grouped_tahoe_age_1990, grouped_tahoe_age_2000, grouped_tahoe_age_2010, grouped_tahoe_age_2020], ignore_index=True)\n",
    "grouped_tahoe_age.to_excel('Census_Data_Downloads\\grouped_tahoe_age_10_year.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_categories_2022 = 'Census_Category_Lists/acs_age_groups.csv'\n",
    "age_data_2022 = age_data.loc[age_data['year_sample']==2022]\n",
    "grouped_tahoe_age_2022 = categorize_values(age_data_2022,acs_categories_2022,'Broad_Category', 'TRPA 5-year Age Categories')\n",
    "grouped_tahoe_age_2022.to_excel('Census_Data_Downloads\\grouped_acs_age_5_year.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize non-Tahoe age data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import from an excel sheet because it's not worth bringing the detailed ones in\n",
    "dtypes = {\n",
    "    'GEO_ID' : str,\n",
    "'value' : int,\n",
    "'state' : str,\n",
    "'MarginOfError' : str,\n",
    "'county' : str,\n",
    "'sample_level' : str,\n",
    "'Geo_Name' : str,\n",
    "'variable_code' : str,\n",
    "'variable_name' : str,\n",
    "'variable_category' : str,\n",
    "'year_sample' : str,\n",
    "'dataset' : str,\n",
    "'census_geom_year' : str,\n",
    "'TRPAID' : str,\n",
    "}\n",
    "\n",
    "non_tahoe_age = pd.read_csv(\"non_tahoe_age_data.csv\", dtype= dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_categories = 'Census_Category_Lists/dec_age_categories.csv'\n",
    "dec_categories_2020 = 'Census_Category_Lists/dec_age_categories_2020.csv'\n",
    "non_tahoe_age_2010 = non_tahoe_age.loc[non_tahoe_age['year_sample']=='2010']\n",
    "non_tahoe_age_2000 = non_tahoe_age.loc[non_tahoe_age['year_sample']=='2000']\n",
    "non_tahoe_age_2020 = non_tahoe_age.loc[non_tahoe_age['year_sample']=='2020']\n",
    "\n",
    "grouped_non_tahoe_age_2000 = categorize_values(non_tahoe_age_2000, dec_categories ,'Census Category with Sex', 'TRPA Census Age Sex Categories Grouped: ')\n",
    "grouped_non_tahoe_age_2010 = categorize_values(non_tahoe_age_2010, dec_categories ,'Census Category with Sex', 'TRPA Census Age Sex Categories Grouped: ')\n",
    "grouped_non_tahoe_age_2020 = categorize_values(non_tahoe_age_2020, dec_categories_2020 ,'Census Category with Sex', 'TRPA Census Age Sex Categories Grouped: ')\n",
    "\n",
    "grouped_non_tahoe_age = pd.concat([grouped_non_tahoe_age_2000, grouped_non_tahoe_age_2010, grouped_non_tahoe_age_2020], ignore_index=True)\n",
    "grouped_non_tahoe_age.to_excel('Census_Data_Downloads\\grouped_non_tahoe_age.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_categories = 'Census_Category_Lists/dec_age_categories.csv'\n",
    "dec_categories_2020 = 'Census_Category_Lists/dec_age_categories_2020.csv'\n",
    "non_tahoe_age_2010 = non_tahoe_age.loc[non_tahoe_age['year_sample']=='2010']\n",
    "non_tahoe_age_2000 = non_tahoe_age.loc[non_tahoe_age['year_sample']=='2000']\n",
    "non_tahoe_age_2020 = non_tahoe_age.loc[non_tahoe_age['year_sample']=='2020']\n",
    "\n",
    "grouped_non_tahoe_age_2000 = categorize_values(non_tahoe_age_2000, dec_categories ,'Census Category', 'TRPA Census Age Categories Grouped: ')\n",
    "grouped_non_tahoe_age_2010 = categorize_values(non_tahoe_age_2010, dec_categories ,'Census Category', 'TRPA Census Age Categories Grouped: ')\n",
    "grouped_non_tahoe_age_2020 = categorize_values(non_tahoe_age_2020, dec_categories_2020 ,'Census Category', 'TRPA Census Age Categories Grouped: ')\n",
    "\n",
    "grouped_non_tahoe_age = pd.concat([grouped_non_tahoe_age_2000, grouped_non_tahoe_age_2010, grouped_non_tahoe_age_2020], ignore_index=True)\n",
    "grouped_non_tahoe_age.to_excel('Census_Data_Downloads\\grouped_non_tahoe_age_no_sex.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_categories = 'Census_Category_Lists/dec_age_categories.csv'\n",
    "dec_categories_2020 = 'Census_Category_Lists/dec_age_categories_2020.csv'\n",
    "non_tahoe_age_2010 = non_tahoe_age.loc[non_tahoe_age['year_sample']=='2010']\n",
    "non_tahoe_age_2000 = non_tahoe_age.loc[non_tahoe_age['year_sample']=='2000']\n",
    "non_tahoe_age_2020 = non_tahoe_age.loc[non_tahoe_age['year_sample']=='2020']\n",
    "\n",
    "grouped_non_tahoe_age_2000 = categorize_values(non_tahoe_age_2000, dec_categories ,'Ten Year Category', 'TRPA 10-year Age Categories Grouped: ')\n",
    "grouped_non_tahoe_age_2010 = categorize_values(non_tahoe_age_2010, dec_categories ,'Ten Year Category', 'TRPA 10-year Age Categories Grouped: ')\n",
    "grouped_non_tahoe_age_2020 = categorize_values(non_tahoe_age_2020, dec_categories_2020 ,'Ten Year Category', 'TRPA 10-year Age Categories Grouped: ')\n",
    "\n",
    "grouped_non_tahoe_age = pd.concat([grouped_non_tahoe_age_2000, grouped_non_tahoe_age_2010, grouped_non_tahoe_age_2020], ignore_index=True)\n",
    "grouped_non_tahoe_age.to_excel('Census_Data_Downloads\\grouped_non_tahoe_age_10_year.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/28'\n",
    "\n",
    "feature_layer = FeatureLayer(service_url)\n",
    "query_result = feature_layer.query()\n",
    "# Convert the query result to a list of dictionaries\n",
    "feature_list = query_result.features\n",
    "\n",
    "# Create a pandas DataFrame from the list of dictionaries\n",
    "census_data = pd.DataFrame([feature.attributes for feature in feature_list])\n",
    "age_data_1990 = census_data.loc[(census_data['variable_category']=='TRPA Census Age Categories Grouped: Age')&(census_data['sample_level']=='County')\n",
    "                                & (census_data['year_sample']==1990)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_categories_1990 = 'Census_Category_Lists/age_categories_1990_updated.csv'\n",
    "grouped_tahoe_age_1990 = categorize_values(age_data_1990, dec_categories_1990 ,'Ten Year Category', 'TRPA 10-year Age Categories Grouped: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_tahoe_age_1990.to_excel('grouped_tahoe_age_1990_2.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize Vehicle Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/28'\n",
    "\n",
    "feature_layer = FeatureLayer(service_url)\n",
    "query_result = feature_layer.query()\n",
    "# Convert the query result to a list of dictionaries\n",
    "feature_list = query_result.features\n",
    "\n",
    "# Create a pandas DataFrame from the list of dictionaries\n",
    "census_data = pd.DataFrame([feature.attributes for feature in feature_list])\n",
    "vehicle_data = census_data.loc[(census_data['variable_category']=='Tenure by Vehicles Available')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_categories = 'Census_Category_Lists/vehicle_categories.csv'\n",
    "grouped_vehicle_data = categorize_values(vehicle_data, vehicle_categories, 'Broad Category', 'Household Vehicle Numbers: ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_vehicle_data.to_excel('Census_Data_Downloads/vehicle_data.xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get 1990 Miscellanous vacant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/28'\n",
    "\n",
    "feature_layer = FeatureLayer(service_url)\n",
    "query_result = feature_layer.query()\n",
    "# Convert the query result to a list of dictionaries\n",
    "feature_list = query_result.features\n",
    "\n",
    "# Create a pandas DataFrame from the list of dictionaries\n",
    "census_data = pd.DataFrame([feature.attributes for feature in feature_list])\n",
    "housing_data = census_data.loc[census_data['variable_name'].isin(['Total Housing Units: Vacant', 'Vacant Housing Units: Seasonal, recreational, or occasional use'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vacant_other(group):\n",
    "    x_value = group.loc[group['variable_name']=='Total Housing Units: Vacant','value'].values[0]\n",
    "    y_value = group.loc[group['variable_name']=='Vacant Housing Units: Seasonal, recreational, or occasional use','value'].values[0]\n",
    "    return x_value - y_value\n",
    "housing_data = census_data.loc[census_data['variable_name'].isin(['Total Housing Units: Vacant', 'Vacant Housing Units: Seasonal, recreational, or occasional use'])]\n",
    "housing_data =housing_data.loc[housing_data['year_sample']==1990]\n",
    "\n",
    "columns_to_exclude = ['variable_name', 'value', 'variable_code', 'OBJECTID']\n",
    "\n",
    "# Use list comprehension to get all column names except the ones to exclude\n",
    "selected_columns = [col for col in housing_data.columns if col not in columns_to_exclude]\n",
    "\n",
    "\n",
    "housing_data['Difference'] = housing_data.groupby(selected_columns).apply(vacant_other).reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorize Language Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/28'\n",
    "\n",
    "feature_layer = FeatureLayer(service_url)\n",
    "query_result = feature_layer.query()\n",
    "# Convert the query result to a list of dictionaries\n",
    "feature_list = query_result.features\n",
    "\n",
    "# Create a pandas DataFrame from the list of dictionaries\n",
    "census_data = pd.DataFrame([feature.attributes for feature in feature_list])\n",
    "language_data = census_data.loc[(census_data['variable_category']=='Language')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_categories = 'Census_Category_Lists/Language_Categories.csv'\n",
    "grouped_language_data = categorize_values(language_data, language_categories, 'English Fluency', 'English Fluency: ')\n",
    "grouped_language_data = grouped_language_data.dropna(subset=['variable_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_language_data.to_excel('Census_Data_Downloads/language_data.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
