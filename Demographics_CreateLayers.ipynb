{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate Development and Population"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T18:41:56.378006Z",
     "start_time": "2023-08-18T18:41:54.689481Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# import packages\n",
    "import arcpy\n",
    "import os\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy.engine import URL, create_engine\n",
    "from arcgis import GIS\n",
    "from arcgis.features import GeoAccessor, GeoSeriesAccessor\n",
    "\n",
    "from arcgis.features import FeatureLayer\n",
    "\n",
    "# set overwrite to true\n",
    "arcpy.env.overwriteOutput = True\n",
    "\n",
    "# enterprise Geodatabase connection\n",
    "sdeBase = \"F:\\GIS\\DB_CONNECT\\Vector.sde\"\n",
    "\n",
    "# setup sql connection\n",
    "connection_string = \"DRIVER={ODBC Driver 17 for SQL Server};SERVER=sql12;DATABASE=sde;UID=sde;PWD=staff\"\n",
    "connection_url    = URL.create(\"mssql+pyodbc\", query={\"odbc_connect\": connection_string})\n",
    "connection        = create_engine(connection_url)\n",
    "\n",
    "# set workspace\n",
    "arcpy.env.workspace = \"F:\\GIS\\PROJECTS\\ResearchAnalysis\\Demographics\\Workspace.gdb\"\n",
    "workspace           = r\"F:\\GIS\\PROJECTS\\ResearchAnalysis\\Demographics\\Workspace.gdb\"\n",
    "workspace_folder    = r\"F:\\GIS\\PROJECTS\\ResearchAnalysis\\Demographics\"\n",
    "\n",
    "# in memory output file path\n",
    "memory_workspace = \"memory\" + \"\\\\\"\n",
    "\n",
    "# Connect to TRPA Enterprise GIS Portal\n",
    "portal_url = \"https://maps.trpa.org/portal\"\n",
    "gis = GIS(portal_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Get Data from Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-15T16:46:21.842254Z",
     "start_time": "2023-08-15T16:29:10.131684Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# sde census features\n",
    "censusGeography = os.path.join(sdeBase, \n",
    "                    \"sde.SDE.Census\\sde.SDE.Tahoe_Census_Geography\")\n",
    "\n",
    "# make feature layer of blocks from 2020\n",
    "blockLayer2020 = arcpy.MakeFeatureLayer_management(\n",
    "                        censusGeography, \n",
    "                        \"Tahoe_Blocks_2020\", \n",
    "                        \"YEAR = 2020 And GEOGRAPHY = 'block'\")\n",
    "\n",
    "# make feature layer of blocks from 2010\n",
    "blockLayer2010 = arcpy.MakeFeatureLayer_management(\n",
    "                        censusGeography, \n",
    "                        \"Tahoe_Blocks_2010\", \n",
    "                        \"YEAR = 2010 And GEOGRAPHY = 'block'\")\n",
    "\n",
    "\n",
    "# export copy to workspace\n",
    "arcpy.conversion.FeatureClassToGeodatabase(blockLayer2020,workspace)\n",
    "\n",
    "# export copy to workspace\n",
    "arcpy.conversion.FeatureClassToGeodatabase(blockLayer2010,workspace)\n",
    "\n",
    "# field list for new block feature class\n",
    "field_list_2010 = [\n",
    " # Add fields to block group 2010\n",
    " 'Block_Population_2010',\n",
    " 'Block_HousingUnits_2010',\n",
    " 'Block_Occupied_2010',\n",
    " 'Block_Vacant_2010',\n",
    " 'Block_Seasonal_2010',\n",
    " 'Block_ResidenatialUnits_2010',\n",
    "]\n",
    "\n",
    "field_list_2020=[\n",
    "# Add fields to block group 2020\n",
    " 'Block_Population_2020',\n",
    " 'Block_HousingUnits_2020',\n",
    " 'Block_Occupied_2020',\n",
    " 'Block_Vacant_2020',\n",
    " 'Block_Seasonal_2020',\n",
    " 'Block_ResidenatialUnits_2020',\n",
    " # Add fields for % change\n",
    " 'Block_PercentChange_Population',\n",
    " 'Block_PercentChange_HousingUnits',\n",
    " 'Block_PercentChange_ResidentialUnits',\n",
    "]\n",
    "\n",
    "# get at workspace blocks\n",
    "tahoeBlocks2010 = os.path.join(workspace, 'Tahoe_Blocks_2010')\n",
    "# get at workspace blocks\n",
    "tahoeBlocks2020 = os.path.join(workspace, 'Tahoe_Blocks_2020')\n",
    "\n",
    "# add fields to workspace blocks\n",
    "for field in field_list_2010:\n",
    "    arcpy.AddField_management(tahoeBlocks2010, field, \"DOUBLE\")\n",
    "\n",
    "for field in field_list_2020:\n",
    "    arcpy.AddField_management(tahoeBlocks2020, field, \"DOUBLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Get data from feature service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T21:43:05.782344Z",
     "start_time": "2023-08-16T21:42:56.234334Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Search for the feature service by keyword\n",
    "feature_layer_item = gis.content.search(query=\"Demographics\", item_type=\"Feature Layer\")[0]\n",
    "\n",
    "# feature sub layer name to get\n",
    "sublayer_name = \"Tahoe Census Geography\"\n",
    "\n",
    "# Query the sublayer by name\n",
    "sublayer = None\n",
    "for layer in feature_layer_item.layers:\n",
    "    if layer.properties.name == sublayer_name:\n",
    "        sublayer = layer\n",
    "        break\n",
    "\n",
    "# create a Spatially Enabled DataFrame\n",
    "sdfCensus = pd.DataFrame.spatial.from_layer(sublayer)\n",
    "\n",
    "# create data frames from filter for block and year\n",
    "sdfBlocks2020 = sdfCensus[(sdfCensus['GEOGRAPHY'] == 'block') & (sdfCensus['YEAR'] == 2020)]\n",
    "sdfBlocks2010 = sdfCensus[(sdfCensus['GEOGRAPHY'] == 'block') & (sdfCensus['YEAR'] == 2010)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T18:18:43.839790Z",
     "start_time": "2023-08-17T18:18:35.375652Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Search for the feature layer by keyword\n",
    "feature_layer_item = gis.content.search(query=\"Demographics\", item_type=\"Feature Layer\")[0]\n",
    "\n",
    "# # Access the first result (assuming it's the one you want)\n",
    "# feature_layer_item = search_result[0]\n",
    "table_name = \"Census Data\"\n",
    "\n",
    "# Query the sublayer by name\n",
    "subtable = None\n",
    "for table in feature_layer_item.tables:\n",
    "    if table.properties.name == table_name:\n",
    "        subtable = table\n",
    "        break\n",
    "\n",
    "# create a Spatially Enabled DataFrame object\n",
    "dfCensus = pd.DataFrame.spatial.from_layer(subtable)\n",
    "\n",
    "# Define the filter conditions for each field\n",
    "conditionBlock      = dfCensus['sample_level']  == 'block'\n",
    "condition2010       = dfCensus['year_sample']   == 2010\n",
    "condition2020       = dfCensus['year_sample']   == 2020\n",
    "conditionPopulation = dfCensus['variable_name'] == 'Total Population'\n",
    "conditionHousing    = dfCensus['variable_name'] == 'Total Housing Units'\n",
    "conditionOccupied   = dfCensus['variable_name'] == 'Total Housing Units: Occupied'\n",
    "conditionVacant     = dfCensus['variable_name'] == 'Total Housing Units: Vacant'\n",
    "conditionSeasonal   = dfCensus['variable_name'] == 'Vacant Housing Units: Seasonal, recreational, or occasional use'\n",
    "\n",
    "# filter to create new dfs by variable name\n",
    "dfBlockPop2010           =  dfCensus.loc[conditionBlock & condition2010 & conditionPopulation].copy()\n",
    "dfBlockUnits2010         =  dfCensus.loc[conditionBlock & condition2010 & conditionHousing].copy()\n",
    "dfBlockUnitsOccupied2010 =  dfCensus.loc[conditionBlock & condition2010 & conditionOccupied].copy()\n",
    "dfBlockUnitsVacant2010   =  dfCensus.loc[conditionBlock & condition2010 & conditionVacant].copy()\n",
    "dfBlockUnitsSeasonal2010 =  dfCensus.loc[conditionBlock & condition2010 & conditionSeasonal].copy()\n",
    "\n",
    "# create 2020 data frames from sql query\n",
    "dfBlockPop2020           =  dfCensus[conditionBlock & condition2020 & conditionPopulation].copy()\n",
    "dfBlockUnits2020         =  dfCensus[conditionBlock & condition2020 & conditionHousing].copy()\n",
    "dfBlockUnitsOccupied2020 =  dfCensus[conditionBlock & condition2020 & conditionOccupied].copy()\n",
    "dfBlockUnitsVacant2020   =  dfCensus[conditionBlock & condition2020 & conditionVacant].copy()\n",
    "dfBlockUnitsSeasonal2020 =  dfCensus[conditionBlock & condition2020 & conditionSeasonal].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Join Data Frames and Blocks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Add Data Frame name as a prefix to column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T21:45:05.916995Z",
     "start_time": "2023-08-16T21:45:05.844254Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_list = [\n",
    "    dfBlockPop2010,          \n",
    "    dfBlockUnits2010,         \n",
    "    dfBlockUnitsOccupied2010, \n",
    "    dfBlockUnitsVacant2010,  \n",
    "    dfBlockUnitsSeasonal2010,\n",
    "    dfBlockPop2020,           \n",
    "    dfBlockUnits2020,         \n",
    "    dfBlockUnitsOccupied2020, \n",
    "    dfBlockUnitsVacant2020,\n",
    "    dfBlockUnitsSeasonal2020\n",
    "]\n",
    "\n",
    "# specify fields to keep\n",
    "fields_to_keep = ['TRPAID', 'value']\n",
    "\n",
    "# Loop through each DataFrame and drop the specified fields\n",
    "for dataframe in df_list:\n",
    "    # drop columns not in list\n",
    "    dataframe.drop(columns=[col for col in dataframe.columns if col not in fields_to_keep], inplace=True)  \n",
    "    # Exclude the field name you want to skip\n",
    "    field_to_exclude = \"TRPAID\"\n",
    "    # keep neccessary columns\n",
    "    included_columns = [col for col in dataframe.columns if col != field_to_exclude]\n",
    "    # get the dataframe name as a string\n",
    "    df_name = [name for name in globals() if globals()[name] is dataframe][0]\n",
    "    dataframe['TRPAID'].astype(str)\n",
    "    # Add DataFrame name as a prefix to included column names\n",
    "    new_columns = [f\"{df_name}_{col}\" for col in included_columns]\n",
    "    dataframe.columns =  [\"TRPAID\"]+ new_columns\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Merge data frames to spatial data frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T21:45:08.818677Z",
     "start_time": "2023-08-16T21:45:08.636415Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_list_2010 = [\n",
    "    dfBlockPop2010,          \n",
    "    dfBlockUnits2010,         \n",
    "    dfBlockUnitsOccupied2010, \n",
    "    dfBlockUnitsVacant2010,  \n",
    "    dfBlockUnitsSeasonal2010\n",
    "]\n",
    "\n",
    "df_list_2020=[\n",
    "    dfBlockPop2020,           \n",
    "    dfBlockUnits2020,         \n",
    "    dfBlockUnitsOccupied2020, \n",
    "    dfBlockUnitsVacant2020,\n",
    "    dfBlockUnitsSeasonal2020\n",
    "]\n",
    "# Join DataFrames using merge\n",
    "for df in df_list_2010:\n",
    "    sdfBlocks2010 = sdfBlocks2010.merge(df, on='TRPAID', how=\"left\")\n",
    "# Join DataFrames using merge\n",
    "for df in df_list_2020:\n",
    "    sdfBlocks2020 = sdfBlocks2020.merge(df, on='TRPAID', how=\"left\")\n",
    "    \n",
    "# set new field values\n",
    "sdfBlocks2010['Block_Population_2010']   = sdfBlocks2010['dfBlockPop2010_value']\n",
    "sdfBlocks2010['Block_HousingUnits_2010'] = sdfBlocks2010['dfBlockUnits2010_value']\n",
    "sdfBlocks2010['Block_Occupied_2010']     = sdfBlocks2010['dfBlockUnitsOccupied2010_value']\n",
    "sdfBlocks2010['Block_Vacant_2010']       = sdfBlocks2010['dfBlockUnitsVacant2010_value']\n",
    "sdfBlocks2010['Block_Seasonal_2010']     = sdfBlocks2010['dfBlockUnitsSeasonal2010_value']\n",
    "\n",
    "sdfBlocks2020['Block_Population_2020']   = sdfBlocks2020['dfBlockPop2020_value']\n",
    "sdfBlocks2020['Block_HousingUnits_2020'] = sdfBlocks2020['dfBlockUnits2020_value']\n",
    "sdfBlocks2020['Block_Occupied_2020']     = sdfBlocks2020['dfBlockUnitsOccupied2020_value']\n",
    "sdfBlocks2020['Block_Vacant_2020']       = sdfBlocks2020['dfBlockUnitsVacant2020_value']\n",
    "sdfBlocks2020['Block_Seasonal_2020']     = sdfBlocks2020['dfBlockUnitsSeasonal2020_value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Export to Data Frames to staging Feature Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T22:09:05.960603Z",
     "start_time": "2023-08-16T22:08:17.55409Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df = sdfBlocks2010\n",
    "\n",
    "numeric_columns = []\n",
    "\n",
    "for column in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        numeric_columns.append(column)\n",
    "        \n",
    "# Fill specified numeric columns with zeros\n",
    "df[numeric_columns] = df[numeric_columns].fillna(0)\n",
    "\n",
    "## Export spatial dataframes to feature class to use in Spatial join\n",
    "sdfBlocks2010.copy().spatial.to_featureclass(os.path.join(workspace, \"Tahoe_Blocks_2010_Staging\"), sanitize_columns=False)\n",
    "\n",
    "df = sdfBlocks2020\n",
    "\n",
    "numeric_columns = []\n",
    "\n",
    "for column in df.columns:\n",
    "    if pd.api.types.is_numeric_dtype(df[column]):\n",
    "        numeric_columns.append(column)\n",
    "        \n",
    "# Fill specified numeric columns with zeros\n",
    "df[numeric_columns] = df[numeric_columns].fillna(0)\n",
    "\n",
    "## Export spatial dataframes to feature class to use in Spatial join\n",
    "sdfBlocks2020.copy().spatial.to_featureclass(os.path.join(workspace, \"Tahoe_Blocks_2020_Staging\"), sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Spatial Joins of 2022 development and 2010 census block data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T22:09:06.175100Z",
     "start_time": "2023-08-16T22:09:05.961168Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "field_names = [f.name for f in arcpy.ListFields(\"Tahoe_Blocks_2010_Staging\")]\n",
    "print(field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T22:09:06.857400Z",
     "start_time": "2023-08-16T22:09:06.2621Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "field_names = [f.name for f in arcpy.ListFields(\"Tahoe_Blocks_2020_Staging\")]\n",
    "print(field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T22:11:55.310217Z",
     "start_time": "2023-08-16T22:11:41.66954Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "target_feature_class = os.path.join(workspace, \"Tahoe_Blocks_2020_Staging\")\n",
    "join_feature_class   = os.path.join(workspace, \"Tahoe_Blocks_2010_Staging\")\n",
    "output_feature_class = \"SpatialJoin_Blocks2020_Blocks2010\"\n",
    "\n",
    "# List of input and join field names\n",
    "input_field_names = [ \n",
    "                'GEOGRAPHY', 'GEOID', 'GlobalID', 'NEIGHBORHOOD', 'STATE', 'TRPAID', 'YEAR', \n",
    "                'Block_Population_2020', 'Block_HousingUnits_2020', \n",
    "                'Block_Occupied_2020', 'Block_Vacant_2020', 'Block_Seasonal_2020'\n",
    "                    ]\n",
    "\n",
    "join_field_names = [ 'YEAR',\n",
    "                    'Block_Population_2010', 'Block_HousingUnits_2010', \n",
    "                    'Block_Occupied_2010', 'Block_Vacant_2010', 'Block_Seasonal_2010'\n",
    "                   ]\n",
    "\n",
    "# List of fields to be joined using SUM\n",
    "fields_to_sum = [\n",
    "                    'Block_Population_2010', 'Block_HousingUnits_2010', \n",
    "                    'Block_Occupied_2010', 'Block_Vacant_2010', 'Block_Seasonal_2010'\n",
    "                ]\n",
    "\n",
    "# Create a field map object\n",
    "field_mappings = arcpy.FieldMappings()\n",
    "\n",
    "# Get the field info for the target feature class\n",
    "target_field_info = arcpy.ListFields(target_feature_class)\n",
    "\n",
    "# Add fields from the target feature class to the field mappings\n",
    "for field in target_field_info:\n",
    "    if field.name in input_field_names:\n",
    "        input_field_map = arcpy.FieldMap()\n",
    "        input_field_map.addInputField(target_feature_class, field.name)\n",
    "        # Set the merge rule to SUM for selected fields\n",
    "        if field.name in fields_to_sum:\n",
    "            input_field_map.mergeRule = \"SUM\"\n",
    "        \n",
    "        field_mappings.addFieldMap(input_field_map)\n",
    "\n",
    "# Get the field info for the join feature class\n",
    "join_field_info = arcpy.ListFields(join_feature_class)\n",
    "\n",
    "# Add fields from the join feature class to the field mappings\n",
    "for field in join_field_info:\n",
    "    if field.name in join_field_names:\n",
    "        join_field_map = arcpy.FieldMap()\n",
    "        join_field_map.addInputField(join_feature_class, field.name)\n",
    "        # Set the merge rule to SUM for selected fields\n",
    "        if field.name in fields_to_sum:\n",
    "            join_field_map.mergeRule = \"SUM\"\n",
    "        # add join fields to field mappings\n",
    "        field_mappings.addFieldMap(join_field_map)\n",
    "\n",
    "# Perform the spatial join using the specified field mappings\n",
    "arcpy.analysis.SpatialJoin(\n",
    "                    target_feature_class, \n",
    "                    join_feature_class, \n",
    "                    output_feature_class,\n",
    "                    join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "                    join_type=\"KEEP_ALL\",\n",
    "                    field_mapping = field_mappings,\n",
    "                    match_option=\"HAVE_THEIR_CENTER_IN\",\n",
    "                    search_radius=None,\n",
    "                    distance_field_name=\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Spatial Join Development rights to Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-16T23:07:13.642213Z",
     "start_time": "2023-08-16T23:07:12.315787Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set the definition query\n",
    "definition_query = \"YEAR = 2022\"\n",
    "\n",
    "# Create a feature layer\n",
    "parcel_development_2022 = arcpy.management.MakeFeatureLayer(\n",
    "                            in_features=os.path.join(workspace, 'Parcel_Development'),\n",
    "                            out_layer=\"Parcel Development 2022\",\n",
    "                            where_clause=definition_query\n",
    "                            )[0]\n",
    "\n",
    "field_names = [f.name for f in arcpy.ListFields(parcel_development_2022)]\n",
    "print(field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T03:33:40.788585Z",
     "start_time": "2023-08-17T03:33:20.819910Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set the definition query\n",
    "definition_query = \"YEAR = 2012\"\n",
    "\n",
    "# Create a feature layer\n",
    "parcel_development_2012 = arcpy.management.MakeFeatureLayer(\n",
    "                            in_features=os.path.join(workspace, 'Parcel_Development'),\n",
    "                            out_layer=\"Parcel Development 2012\",\n",
    "                            where_clause=definition_query\n",
    "                            )[0]\n",
    "\n",
    "# export to points to get a layer that will join\n",
    "outFeatureClass = \"ParcelDev2012_points\"\n",
    "\n",
    "# Use FeatureToPoint function to find a point inside each park\n",
    "arcpy.management.FeatureToPoint(parcel_development_2012, outFeatureClass, \"INSIDE\")\n",
    "\n",
    "# fields\n",
    "field_names = [f.name for f in arcpy.ListFields(parcel_development_2012)]\n",
    "print(field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T03:34:04.457921Z",
     "start_time": "2023-08-17T03:33:40.791123Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set the definition query\n",
    "definition_query = \"YEAR = 2022\"\n",
    "\n",
    "# Create a feature layer\n",
    "parcel_development_2012 = arcpy.management.MakeFeatureLayer(\n",
    "                            in_features=os.path.join(workspace, 'Parcel_Development'),\n",
    "                            out_layer=\"Parcel Development 2022\",\n",
    "                            where_clause=definition_query\n",
    "                            )[0]\n",
    "\n",
    "# export to points to get a layer that will join\n",
    "outFeatureClass = \"ParcelDev2022_points\"\n",
    "\n",
    "# Use FeatureToPoint function to find a point inside each park\n",
    "arcpy.management.FeatureToPoint(parcel_development_2012, outFeatureClass, \"INSIDE\")\n",
    "\n",
    "# fields\n",
    "field_names = [f.name for f in arcpy.ListFields(parcel_development_2012)]\n",
    "print(field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T04:12:34.839871Z",
     "start_time": "2023-08-17T04:12:19.74765Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Spatial join to parcel development\n",
    "target_feature_class = os.path.join(workspace, \"SpatialJoin_Blocks2020_Blocks2010\")\n",
    "join_feature_class   = \"ParcelDev2012_points\"\n",
    "output_feature_class = \"SpatialJoin_Blocks2020_Blocks2010_ParcelDev2012\"\n",
    "\n",
    "# List of input and join field names\n",
    "input_field_names = [ \n",
    "                'GEOGRAPHY', 'GEOID', 'GlobalID', 'NEIGHBORHOOD', 'STATE', 'TRPAID', 'YEAR', \n",
    "                'Block_Population_2020', 'Block_HousingUnits_2020', \n",
    "                'Block_Occupied_2020', 'Block_Vacant_2020', 'Block_Seasonal_2020',\n",
    "                'Block_Population_2010', 'Block_HousingUnits_2010', \n",
    "                'Block_Occupied_2010', 'Block_Vacant_2010', 'Block_Seasonal_2010'\n",
    "                    ]\n",
    "\n",
    "join_field_names = [ 'Residential_Units'\n",
    "                   ]\n",
    "\n",
    "# List of fields to be joined using SUM\n",
    "fields_to_sum = ['Residential_Units'\n",
    "                ]\n",
    "\n",
    "# Create a field map object\n",
    "field_mappings = arcpy.FieldMappings()\n",
    "\n",
    "# Get the field info for the target feature class\n",
    "target_field_info = arcpy.ListFields(target_feature_class)\n",
    "\n",
    "# Add fields from the target feature class to the field mappings\n",
    "for field in target_field_info:\n",
    "    if field.name in input_field_names:\n",
    "        input_field_map = arcpy.FieldMap()\n",
    "        input_field_map.addInputField(target_feature_class, field.name)\n",
    "        # Set the merge rule to SUM for selected fields\n",
    "        if field.name in fields_to_sum:\n",
    "            input_field_map.mergeRule = \"SUM\"\n",
    "        \n",
    "        field_mappings.addFieldMap(input_field_map)\n",
    "\n",
    "# Get the field info for the join feature class\n",
    "join_field_info = arcpy.ListFields(join_feature_class)\n",
    "\n",
    "# Add fields from the join feature class to the field mappings\n",
    "for field in join_field_info:\n",
    "    if field.name in join_field_names:\n",
    "        join_field_map = arcpy.FieldMap()\n",
    "        join_field_map.addInputField(join_feature_class, field.name)\n",
    "        # Set the merge rule to SUM for selected fields\n",
    "        if field.name in fields_to_sum:\n",
    "            join_field_map.mergeRule = \"SUM\"\n",
    "        # add join fields to field mappings\n",
    "        field_mappings.addFieldMap(join_field_map)\n",
    "\n",
    "# Perform the spatial join using the specified field mappings\n",
    "arcpy.analysis.SpatialJoin(\n",
    "                    target_feature_class, \n",
    "                    join_feature_class, \n",
    "                    output_feature_class,\n",
    "                    join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "                    join_type=\"KEEP_ALL\",\n",
    "                    field_mapping = field_mappings,\n",
    "                    match_option=\"CONTAINS\",\n",
    "                    search_radius=None,\n",
    "                    distance_field_name=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T04:12:39.298905Z",
     "start_time": "2023-08-17T04:12:34.840504Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set local variables\n",
    "in_table = os.path.join(workspace,\"SpatialJoin_Blocks2020_Blocks2010_ParcelDev2012\") \n",
    "field = \"Residential_Units\"\n",
    "new_field_name = \"Residential_Units_2012\"\n",
    "new_field_alias = \"Residential Units 2012\"\n",
    "field_type = \"LONG\"\n",
    "\n",
    "# Alter the properties of a non nullable, short data type field to become a text field\n",
    "arcpy.management.AlterField(in_table,\n",
    "                            field,\n",
    "                            new_field_name,\n",
    "                            new_field_alias,\n",
    "                            field_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T04:50:26.909373Z",
     "start_time": "2023-08-17T04:50:09.66490Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Spatial join to parcel development\n",
    "target_feature_class = os.path.join(workspace, \"SpatialJoin_Blocks2020_Blocks2010_ParcelDev2012\")\n",
    "join_feature_class   = \"ParcelDev2022_points\"\n",
    "output_feature_class = \"SpatialJoin_Blocks2020_Blocks2010_ParcelDev2012_ParcelDev2022\"\n",
    "\n",
    "# List of input and join field names\n",
    "input_field_names = [ \n",
    "                'GEOGRAPHY', 'GEOID', 'GlobalID', 'NEIGHBORHOOD', 'STATE', 'TRPAID', 'YEAR', \n",
    "                'Block_Population_2020', 'Block_HousingUnits_2020', \n",
    "                'Block_Occupied_2020', 'Block_Vacant_2020', 'Block_Seasonal_2020',\n",
    "                'Block_Population_2010', 'Block_HousingUnits_2010', \n",
    "                'Block_Occupied_2010', 'Block_Vacant_2010', 'Block_Seasonal_2010', 'Residential_Units_2012'\n",
    "                    ]\n",
    "\n",
    "join_field_names = ['Residential_Units']\n",
    "\n",
    "# List of fields to be joined using SUM\n",
    "fields_to_sum = ['Residential_Units']\n",
    "\n",
    "# Create a field map object\n",
    "field_mappings = arcpy.FieldMappings()\n",
    "\n",
    "# Get the field info for the target feature class\n",
    "target_field_info = arcpy.ListFields(target_feature_class)\n",
    "\n",
    "# Add fields from the target feature class to the field mappings\n",
    "for field in target_field_info:\n",
    "    if field.name in input_field_names:\n",
    "        input_field_map = arcpy.FieldMap()\n",
    "        input_field_map.addInputField(target_feature_class, field.name)\n",
    "        # Set the merge rule to SUM for selected fields\n",
    "        if field.name in fields_to_sum:\n",
    "            input_field_map.mergeRule = \"SUM\"\n",
    "        \n",
    "        field_mappings.addFieldMap(input_field_map)\n",
    "\n",
    "# Get the field info for the join feature class\n",
    "join_field_info = arcpy.ListFields(join_feature_class)\n",
    "\n",
    "# Add fields from the join feature class to the field mappings\n",
    "for field in join_field_info:\n",
    "    if field.name in join_field_names:\n",
    "        join_field_map = arcpy.FieldMap()\n",
    "        join_field_map.addInputField(join_feature_class, field.name)\n",
    "        # Set the merge rule to SUM for selected fields\n",
    "        if field.name in fields_to_sum:\n",
    "            join_field_map.mergeRule = \"SUM\"\n",
    "        # add join fields to field mappings\n",
    "        field_mappings.addFieldMap(join_field_map)\n",
    "\n",
    "# Perform the spatial join using the specified field mappings\n",
    "arcpy.analysis.SpatialJoin(\n",
    "                    target_feature_class, \n",
    "                    join_feature_class, \n",
    "                    output_feature_class,\n",
    "                    join_operation=\"JOIN_ONE_TO_ONE\",\n",
    "                    join_type=\"KEEP_ALL\",\n",
    "                    field_mapping = field_mappings,\n",
    "                    match_option=\"CONTAINS\",\n",
    "                    search_radius=None,\n",
    "                    distance_field_name=\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T04:50:31.366986Z",
     "start_time": "2023-08-17T04:50:26.910964Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Set local variables\n",
    "in_table = os.path.join(workspace,\"SpatialJoin_Blocks2020_Blocks2010_ParcelDev2012_ParcelDev2022\") \n",
    "field = \"Residential_Units\"\n",
    "new_field_name = \"Residential_Units_2022\"\n",
    "new_field_alias = \"Residential Units 2022\"\n",
    "field_type = \"LONG\"\n",
    "\n",
    "# Alter the properties of a non nullable, short data type field to become a text field\n",
    "arcpy.management.AlterField(in_table,\n",
    "                            field,\n",
    "                            new_field_name,\n",
    "                            new_field_alias,\n",
    "                            field_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T04:50:53.910460Z",
     "start_time": "2023-08-17T04:50:31.367929Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "spJoin = os.path.join(workspace, \"SpatialJoin_Blocks2020_Blocks2010_ParcelDev2012_ParcelDev2022\")\n",
    "arcpy.AddField_management(spJoin, 'Population_PercentChange', \"DOUBLE\")\n",
    "arcpy.AddField_management(spJoin, 'Housing_PercentChange', \"DOUBLE\")\n",
    "arcpy.AddField_management(spJoin, 'Occupied_PercentChange', \"DOUBLE\")\n",
    "arcpy.AddField_management(spJoin, 'Vacant_PercentChange', \"DOUBLE\")\n",
    "arcpy.AddField_management(spJoin, 'Seasonal_PercentChange', \"DOUBLE\")\n",
    "arcpy.AddField_management(spJoin, 'Development_PercentChange', \"DOUBLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T04:52:22.358756Z",
     "start_time": "2023-08-17T04:52:21.749689Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# fields\n",
    "field_names = [f.name for f in arcpy.ListFields(spJoin)]\n",
    "print(field_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-17T04:58:56.956700Z",
     "start_time": "2023-08-17T04:58:55.270249Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Start an edit session\n",
    "edit = arcpy.da.Editor(workspace)\n",
    "edit.startEditing(False, True)\n",
    "\n",
    "# Define the fields\n",
    "field1 = \"Block_Population_2020\"\n",
    "field2 = \"Block_Population_2010\"\n",
    "percent_change_field = \"Population_PercentChange\"\n",
    "\n",
    "# Calculate percent change using an update cursor\n",
    "with arcpy.da.UpdateCursor(spJoin, [field1, field2, percent_change_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None and row[1] is not None and row[0] != 0:\n",
    "            percent_change = ((row[1] - row[0]) / row[0]) * 100\n",
    "            row[2] = percent_change\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "\n",
    "# Define the fields\n",
    "field1 = \"Block_HousingUnits_2020\"\n",
    "field2 = \"Block_HousingUnits_2010\"\n",
    "percent_change_field = \"Housing_PercentChange\"\n",
    "\n",
    "# Calculate percent change using an update cursor\n",
    "with arcpy.da.UpdateCursor(spJoin, [field1, field2, percent_change_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None and row[1] is not None and row[0] != 0:\n",
    "            percent_change = ((row[1] - row[0]) / row[0]) * 100\n",
    "            row[2] = percent_change\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "# Define the fields\n",
    "field1 = \"Block_Occupied_2020\"\n",
    "field2 = \"Block_Occupied_2010\"\n",
    "percent_change_field = \"Occupied_PercentChange\"\n",
    "\n",
    "# Calculate percent change using an update cursor\n",
    "with arcpy.da.UpdateCursor(spJoin, [field1, field2, percent_change_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None and row[1] is not None and row[0] != 0:\n",
    "            percent_change = ((row[1] - row[0]) / row[0]) * 100\n",
    "            row[2] = percent_change\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "# Define the fields\n",
    "field1 = \"Block_Vacant_2020\"\n",
    "field2 = \"Block_Vacant_2010\"\n",
    "percent_change_field = \"Vacant_PercentChange\"\n",
    "\n",
    "# Calculate percent change using an update cursor\n",
    "with arcpy.da.UpdateCursor(spJoin, [field1, field2, percent_change_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None and row[1] is not None and row[0] != 0:\n",
    "            percent_change = ((row[1] - row[0]) / row[0]) * 100\n",
    "            row[2] = percent_change\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "# Define the fields\n",
    "field1 = \"Block_Seasonal_2020\"\n",
    "field2 = \"Block_Seasonal_2010\"\n",
    "percent_change_field = \"Seasonal_PercentChange\"\n",
    "\n",
    "\n",
    "# Calculate percent change using an update cursor\n",
    "with arcpy.da.UpdateCursor(spJoin, [field1, field2, percent_change_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None and row[1] is not None and row[0] != 0:\n",
    "            percent_change = ((row[1] - row[0]) / row[0]) * 100\n",
    "            row[2] = percent_change\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "# Define the fields\n",
    "field1 = \"Residential_Units_2022\"\n",
    "field2 = \"Residential_Units_2012\"\n",
    "percent_change_field = \"Development_PercentChange\"\n",
    "\n",
    "\n",
    "# Calculate percent change using an update cursor\n",
    "with arcpy.da.UpdateCursor(spJoin, [field1, field2, percent_change_field]) as cursor:\n",
    "    for row in cursor:\n",
    "        if row[0] is not None and row[1] is not None and row[0] != 0:\n",
    "            percent_change = ((row[1] - row[0]) / row[0]) * 100\n",
    "            row[2] = percent_change\n",
    "            cursor.updateRow(row)\n",
    "\n",
    "            \n",
    "# Stop the edit session\n",
    "edit.stopEditing(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate TDC data for Block Groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wrapper function for downloading data from Rest feature service into a dataframe\n",
    "def get_census_data(featureset):\n",
    "    service_id = {\n",
    "        'raw_data':'28',\n",
    "        'summaries':'18'\n",
    "    }\n",
    "\n",
    "    service_number = service_id.get(featureset) \n",
    "    service_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/'+service_number\n",
    "\n",
    "    feature_layer = FeatureLayer(service_url)\n",
    "    query_result = feature_layer.query()\n",
    "    # Convert the query result to a list of dictionaries\n",
    "    feature_list = query_result.features\n",
    "\n",
    "    # Create a pandas DataFrame from the list of dictionaries\n",
    "    all_data = pd.DataFrame([feature.attributes for feature in feature_list])\n",
    "\n",
    "    return all_data\n",
    "\n",
    "# Function to aggregate census data to larger categories \n",
    "# Used here to produce categories of interest\n",
    "def categorize_values(census_df, category_csv, category_column, grouping_prefix):\n",
    "    categories = pd.read_csv(category_csv)    \n",
    "    census_df['value'] = census_df['value'].astype(float)\n",
    "    joined_data = census_df.merge(categories, on = 'variable_code', how = 'left')\n",
    "    joined_data.sort_values(by='variable_code', inplace=True)\n",
    "    #This will get rid of any extra columns in the category_csv\n",
    "    group_columns = [column for column in census_df if column not in ['value', 'variable_code', 'variable_name', 'MarginOfError','OBJECTID']]\n",
    "    group_columns.append(category_column)\n",
    "    #grouped_data = joined_data.groupby(group_columns, as_index=False)['value'].sum()    \n",
    "    print(group_columns)\n",
    "    grouped_data = joined_data.groupby(group_columns, as_index=False, dropna=False).agg({'value':'sum',\n",
    "                                                                           'variable_code':lambda x: grouping_prefix +  ', '.join(x)})\n",
    "    \n",
    "    #Need to return this formatted for appending to the table - need to get locations of variable_code and variable name, \n",
    "    #add them in as columns in those locations and then populate them with category column nanme\n",
    "    var_code_col_location = census_df.columns.get_loc('variable_code')\n",
    "    var_name_col_location = census_df.columns.get_loc('variable_name')\n",
    "    var_moe_col_location = census_df.columns.get_loc('MarginOfError')\n",
    "    grouped_data.insert(var_moe_col_location, 'MarginOfError', '')\n",
    "    #grouped_data.insert(var_code_col_location, 'variable_code','Grouped Value')\n",
    "    grouped_data.insert(var_name_col_location, 'variable_name','')\n",
    "    #grouped_data['variable_code'] = grouped_data['variable_code'] +  '_Grouped'\n",
    "    grouped_data['variable_name'] = grouped_data[category_column]\n",
    "    grouped_data['dataset']= grouping_prefix + grouped_data['dataset']\n",
    "    grouped_data['variable_category']= grouping_prefix +  grouped_data['variable_category'] \n",
    "    columns_to_keep = [column for column in census_df if column not in ['OBJECTID']]\n",
    "    grouped_data= grouped_data[columns_to_keep]\n",
    "    return grouped_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download census data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "census_data = get_census_data('raw_data')\n",
    "census_data = census_data.loc[census_data['county']!='510']\n",
    "county_zone = {\n",
    "    '061':'North Lake',\n",
    "    '031':'North Lake',\n",
    "    '005': 'South Lake',\n",
    "    '017':'South Lake'\n",
    "}\n",
    "census_data['Zone'] = census_data['county'].map(county_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This list is based on input from Kira and Rachel\n",
    "TDC_Variables = pd.read_csv(\"Census_Category_Lists\\TDC_categories.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pivot out data to make flat sturucture with one row for each blockgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This could be cool to do for all years so we could show change\n",
    "block_group_data = census_data.loc[(census_data['sample_level']=='block group')&(census_data['year_sample']==2021)]\n",
    "# Map Bipoc, seniors, youth, 0 vehicle households (fillna for no categories)\n",
    "tdc_data = block_group_data.loc[block_group_data['variable_code'].isin(TDC_Variables['variable_code'])]\n",
    "#These will become the feature class column name\n",
    "sort_order = ['TRPAID', 'county', 'tract', 'Total_Population',\n",
    "'Total_Households',\n",
    "'Total_Disability_Population',\n",
    "'Age_Under_18',\n",
    "'Age_18_to_65',\n",
    "'Age_65_and_Over',\n",
    "'With_Disability',\n",
    "'Vehicle_Available_0',\n",
    "'Vehicle_Available_1',\n",
    "'Vehicle_Available_2',\n",
    "'Vehicle_Available_3',\n",
    "'Vehicle_Available_4',\n",
    "'Vehicle_Available_5',\n",
    "'White_Alone',\n",
    "'BIPOC',\n",
    "'Speak_English_Not_Well_Not_at_All'\n",
    "]\n",
    "\n",
    "# Grab the category assigning function\n",
    "tdc_grouped_data = categorize_values(tdc_data, \"Census_Category_Lists\\TDC_categories.csv\", 'Broad Category', \"\")\n",
    "\n",
    "tdc_flat = tdc_grouped_data.pivot(index=['TRPAID', 'county', 'tract'], columns='variable_name', values='value')\n",
    "tdc_flat = tdc_flat.reset_index()\n",
    "tdc_flat = tdc_flat[sort_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download block group geography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Name of the GIS:\", gis.properties.name)\n",
    "feature_layer_item = gis.content.search(query=\"Demographics\", item_type=\"Feature Layer\")[0]\n",
    "print(feature_layer_item.id)\n",
    "item = gis.content.get('3148fb52f80349728d14ce731d6d5b9f')\n",
    "sublayer_name = \"Tahoe Census Geography\"\n",
    "# get census table from the feature service\n",
    "table_name = \"Census Data\"\n",
    "\n",
    "# Query the sublayer by name\n",
    "sublayer = None\n",
    "for layer in item.layers:\n",
    "    if layer.properties.name == sublayer_name:\n",
    "        sublayer = layer\n",
    "        break\n",
    "# Query the features and convert them to a spatially-enabled DataFrame.\n",
    "query_result = sublayer.query()  # You can specify query parameters here if needed.\n",
    "spatial_df = query_result.sdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think we broke this when we switched demographics to just a feature layer\n",
    "feature_layer_item = gis.content.search(query=\"Demographics\", item_type=\"Map Image Layer\")[0]\n",
    "\n",
    "# feature sub layer name to get\n",
    "sublayer_name = \"Tahoe Census Geography\"\n",
    "# get census table from the feature service\n",
    "table_name = \"Census Data\"\n",
    "\n",
    "# Query the sublayer by name\n",
    "sublayer = None\n",
    "for layer in feature_layer_item.layers:\n",
    "    if layer.properties.name == sublayer_name:\n",
    "        sublayer = layer\n",
    "        break\n",
    "\n",
    "query_result = sublayer.query()  # You can specify query parameters here if needed.\n",
    "sdfCensus = query_result.sdf\n",
    "\n",
    "#sdfCensus = pd.DataFrame.spatial.from_layer(sublayer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(sdfCensus, tdc_flat, on='TRPAID', how='inner')\n",
    "columns_drop=['GlobalID', 'YEAR', 'created_date', 'created_user', 'last_edited_date', 'last_edited_user', 'Shape.STArea()', 'Shape.STLength()']\n",
    "merged_df = merged_df.drop(columns=columns_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Export spatial dataframes to feature class to use in Spatial join\n",
    "merged_df.spatial.to_featureclass(os.path.join(workspace, \"Tahoe_BlockGroup_2021_TDC_Values\"), sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_url = 'https://maps.trpa.org/server/rest/services/Demographics/MapServer/32'\n",
    "\n",
    "feature_layer = FeatureLayer(service_url)\n",
    "query_result = feature_layer.query()\n",
    "# Convert the query result to a list of dictionaries\n",
    "feature_list = query_result.features\n",
    "\n",
    "# Create a pandas DataFrame from the list of dictionaries\n",
    "school_enrollment_data = pd.DataFrame([feature.attributes for feature in feature_list])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = arcpy.management.MakeFeatureLayer(\n",
    "    f'https://maps.trpa.org/server/rest/services/Transportation/MapServer/7',\n",
    "    \"temporary_layer\"\n",
    ")[0]\n",
    "\n",
    "# Convert the layer to a spatial DataFrame\n",
    "spatial_df = pd.DataFrame.spatial.from_featureclass(layer)\n",
    "#sdfSchools = pd.DataFrame.spatial.from_layer('https://maps.trpa.org/server/rest/services/Transportation/MapServer/7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Feature Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of layers to create\n",
    "#### Blocks\n",
    "* 2020 population, housing\n",
    "* 2010 population, housing\n",
    "* percent change/bivariate\n",
    "\n",
    "#### Block Group/Tracts Maps\n",
    "* population change\n",
    "* housing vacant/occupied/seasonal change\n",
    "* race dot density\n",
    "* choropleth of population, housing units, median income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T18:51:16.794182Z",
     "start_time": "2023-08-18T18:51:02.559637Z"
    }
   },
   "outputs": [],
   "source": [
    "# Search for the feature service by keyword\n",
    "feature_layer_item = gis.content.search(query=\"Demographics\", item_type=\"Feature Layer\")[0]\n",
    "\n",
    "# feature sub layer name to get\n",
    "sublayer_name = \"Tahoe Census Geography\"\n",
    "# get census table from the feature service\n",
    "table_name = \"Census Data\"\n",
    "\n",
    "# Query the sublayer by name\n",
    "sublayer = None\n",
    "for layer in feature_layer_item.layers:\n",
    "    if layer.properties.name == sublayer_name:\n",
    "        sublayer = layer\n",
    "        break\n",
    "\n",
    "# Query the table by name\n",
    "subtable = None\n",
    "for table in feature_layer_item.tables:\n",
    "    if table.properties.name == table_name:\n",
    "        subtable = table\n",
    "        break\n",
    "        \n",
    "# create a DataFrame from the table\n",
    "sdfCensus = pd.DataFrame.spatial.from_layer(sublayer)\n",
    "dfCensus  = pd.DataFrame.spatial.from_layer(subtable)\n",
    "\n",
    "# create data frames from filter for block and year\n",
    "sdfTract2020 = sdfCensus[(sdfCensus['GEOGRAPHY'] == 'Tract') & (sdfCensus['YEAR'] == 2020)]\n",
    "sdfTract2010 = sdfCensus[(sdfCensus['GEOGRAPHY'] == 'Tract') & (sdfCensus['YEAR'] == 2010)]\n",
    "\n",
    "# Define the filter conditions for each field in the table\n",
    "conditionTract      = dfCensus['sample_level']  == 'tract'\n",
    "conditionLevel      = dfCensus['dataset']       == 'dec/dp'\n",
    "condition2010       = dfCensus['year_sample']   == 2010\n",
    "condition2020       = dfCensus['year_sample']   == 2020\n",
    "conditionPopulation = dfCensus['variable_name'] == 'Total Population'\n",
    "conditionHousing    = dfCensus['variable_name'] == 'Total Housing Units'\n",
    "conditionOccupied   = dfCensus['variable_name'] == 'Total Housing Units: Occupied'\n",
    "conditionVacant     = dfCensus['variable_name'] == 'Total Housing Units: Vacant'\n",
    "conditionSeasonal   = dfCensus['variable_name'] == 'Vacant Housing Units: Seasonal, recreational, or occasional use'\n",
    "\n",
    "# filter to create new dfs by variable name in the table\n",
    "dfTractPop2010           =  dfCensus.loc[conditionTract & condition2010 & conditionPopulation].copy()\n",
    "dfTractUnits2010         =  dfCensus.loc[conditionTract & condition2010 & conditionHousing].copy()\n",
    "dfTractUnitsOccupied2010 =  dfCensus.loc[conditionTract & condition2010 & conditionOccupied].copy()\n",
    "dfTractUnitsVacant2010   =  dfCensus.loc[conditionTract & condition2010 & conditionVacant].copy()\n",
    "dfTractUnitsSeasonal2010 =  dfCensus.loc[conditionTract & condition2010 & conditionSeasonal].copy()\n",
    "\n",
    "# create 2020 data frames \n",
    "dfTractPop2020           =  dfCensus.loc[conditionTract & conditionLevel & condition2020 & conditionPopulation].copy()\n",
    "dfTractUnits2020         =  dfCensus.loc[conditionTract & conditionLevel & condition2020 & conditionHousing].copy()\n",
    "dfTractUnitsOccupied2020 =  dfCensus.loc[conditionTract & conditionLevel & condition2020 & conditionOccupied].copy()\n",
    "dfTractUnitsVacant2020   =  dfCensus.loc[conditionTract & conditionLevel & condition2020 & conditionVacant].copy()\n",
    "dfTractUnitsSeasonal2020 =  dfCensus.loc[conditionTract & conditionLevel & condition2020 & conditionSeasonal].copy()\n",
    "\n",
    "# list of dataframes used to name the value fields\n",
    "df_list = [\n",
    "    dfTractPop2010,          \n",
    "    dfTractUnits2010,         \n",
    "    dfTractUnitsOccupied2010, \n",
    "    dfTractUnitsVacant2010,  \n",
    "    dfTractUnitsSeasonal2010,\n",
    "    dfTractPop2020,           \n",
    "    dfTractUnits2020,         \n",
    "    dfTractUnitsOccupied2020, \n",
    "    dfTractUnitsVacant2020,\n",
    "    dfTractUnitsSeasonal2020\n",
    "]\n",
    "\n",
    "# specify fields to keep in each dataframe from the table queries\n",
    "fields_to_keep = ['TRPAID', 'value']\n",
    "\n",
    "# Loop through each DataFrame and drop the specified fields and \n",
    "# rename the value fields with dataframe names as the prefix\n",
    "for dataframe in df_list:\n",
    "    # drop columns not in list\n",
    "    dataframe.drop(columns=[col for col in dataframe.columns if col not in fields_to_keep], inplace=True)  \n",
    "    # Exclude the field name you want to skip\n",
    "    field_to_exclude = \"TRPAID\"\n",
    "    # keep neccessary columns\n",
    "    included_columns = [col for col in dataframe.columns if col != field_to_exclude]\n",
    "    # get the dataframe name as a string\n",
    "    df_name = [name for name in globals() if globals()[name] is dataframe][0]\n",
    "    dataframe['TRPAID'].astype(str)\n",
    "    # Add DataFrame name as a prefix to included column names\n",
    "    new_columns = [f\"{df_name}_{col}\" for col in included_columns]\n",
    "    # add the new name back to the column list\n",
    "    dataframe.columns =  [\"TRPAID\"]+new_columns\n",
    "    \n",
    "# numeric_columns = []\n",
    "\n",
    "# for column in sdfTract2020.columns:\n",
    "#     if pd.api.types.is_numeric_dtype(sdfTract2020[column]):\n",
    "#         numeric_columns.append(column)\n",
    "        \n",
    "# # Fill specified numeric columns with zeros\n",
    "# sdfTract2020[numeric_columns] = sdfTract2020.loc[numeric_columns].fillna(0)\n",
    "\n",
    "# numeric_columns = []\n",
    "\n",
    "# for column in sdfTract2010.columns:\n",
    "#     if pd.api.types.is_numeric_dtype(sdfTract2010[column]):\n",
    "#         numeric_columns.append(column)\n",
    "        \n",
    "# # # Fill specified numeric columns with zeros\n",
    "# sdfTract2010[numeric_columns] = sdfTract2010.loc[numeric_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T18:51:31.984349Z",
     "start_time": "2023-08-18T18:51:31.966891Z"
    }
   },
   "outputs": [],
   "source": [
    "dfTractUnits2020.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T18:46:26.838732Z",
     "start_time": "2023-08-18T18:46:26.812189Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sdfTract2020.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-18T18:52:46.322962Z",
     "start_time": "2023-08-18T18:51:37.550961Z"
    }
   },
   "outputs": [],
   "source": [
    "# get list of dataframes to merge with 2010 spatial dataframe\n",
    "df_list_2010 = [\n",
    "    dfTractPop2010,          \n",
    "    dfTractUnits2010,         \n",
    "    dfTractUnitsOccupied2010, \n",
    "    dfTractUnitsVacant2010,  \n",
    "    dfTractUnitsSeasonal2010\n",
    "]\n",
    "# get list of dataframes to merge with 2020 spatial dataframe\n",
    "df_list_2020= [\n",
    "    dfTractPop2020,           \n",
    "    dfTractUnits2020,         \n",
    "    dfTractUnitsOccupied2020, \n",
    "    dfTractUnitsVacant2020,\n",
    "    dfTractUnitsSeasonal2020\n",
    "]\n",
    "# merge dataframes to spatial dataframe\n",
    "for df in df_list_2010:\n",
    "    sdfTract2010 = sdfTract2010.merge(df, on='TRPAID', how=\"left\")\n",
    "# so it for 2020\n",
    "for df in df_list_2020:\n",
    "    sdfTract2020 = sdfTract2020.merge(df, on='TRPAID', how=\"left\")\n",
    "    \n",
    "# set new field values\n",
    "sdfTract2010['Tract_Population_2010']   = sdfTract2010['dfTractPop2010_value']\n",
    "sdfTract2010['Tract_HousingUnits_2010'] = sdfTract2010['dfTractUnits2010_value']\n",
    "sdfTract2010['Tract_Occupied_2010']     = sdfTract2010['dfTractUnitsOccupied2010_value']\n",
    "sdfTract2010['Tract_Vacant_2010']       = sdfTract2010['dfTractUnitsVacant2010_value']\n",
    "sdfTract2010['Tract_Seasonal_2010']     = sdfTract2010['dfTractUnitsSeasonal2010_value']\n",
    "\n",
    "sdfTract2020['Tract_Population_2020']   = sdfTract2020['dfTractPop2020_value']\n",
    "sdfTract2020['Tract_HousingUnits_2020'] = sdfTract2020['dfTractUnits2020_value']\n",
    "sdfTract2020['Tract_Occupied_2020']     = sdfTract2020['dfTractUnitsOccupied2020_value']\n",
    "sdfTract2020['Tract_Vacant_2020']       = sdfTract2020['dfTractUnitsVacant2020_value']\n",
    "sdfTract2020['Tract_Seasonal_2020']     = sdfTract2020['dfTractUnitsSeasonal2020_value']\n",
    "\n",
    "\n",
    "# Drop columns not in the list\n",
    "columns_to_drop_2010 = ['Shape__Area', 'Shape__Length', 'created_date', 'created_user', \n",
    "                        'last_edited_date', 'last_edited_user', \n",
    "                        'dfTractPop2010_value', 'dfTractUnits2010_value', \n",
    "                        'dfTractUnitsOccupied2010_value', 'dfTractUnitsVacant2010_value', \n",
    "                        'dfTractUnitsSeasonal2010_value']\n",
    "\n",
    "# Drop columns not in the list\n",
    "columns_to_drop_2020 = ['Shape__Area', 'Shape__Length', 'created_date', 'created_user', \n",
    "                        'last_edited_date', 'last_edited_user', \n",
    "                        'dfTractPop2020_value', 'dfTractUnits2020_value', \n",
    "                        'dfTractUnitsOccupied2020_value', 'dfTractUnitsVacant2020_value', \n",
    "                        'dfTractUnitsSeasonal2020_value']\n",
    "\n",
    "# drop\n",
    "sdfTract2010.drop(columns=columns_to_drop_2010, inplace=True)\n",
    "\n",
    "# drop in place\n",
    "sdfTract2020.drop(columns=columns_to_drop_2020, inplace=True)\n",
    "\n",
    "## Export spatial dataframes to feature class to use in Spatial join\n",
    "sdfTract2010.spatial.to_featureclass(os.path.join(workspace, \"Tahoe_Tract_2010_Values\"), sanitize_columns=False)\n",
    "\n",
    "# Export spatial dataframes to feature class to use in Spatial join\n",
    "sdfTract2020.spatial.to_featureclass(os.path.join(workspace, \"Tahoe_Tract_2020_Values\"), sanitize_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ArcGISPro",
   "language": "Python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
